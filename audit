#!/usr/bin/env php
<?php

/**
 * @file
 * Script to fetch the Archive-It CDX/C record for a given URL, then fetch the content
 * of the request to the URL, then validate its SHA-1 checksum.
 *
 * Input is a file of URLs preserved in Archive-It.
 *
 * @todo:
 * -Add Guzzle error handling.
 * -Sort CDX/C record rows so we can use the most recent for our checksum validation.
 */

require_once 'vendor/autoload.php';

use Base32\Base32;
use Monolog\Logger;
use GuzzleHttp\Psr7;
use GuzzleHttp\Exception\RequestException;
use GuzzleHttp\Exception\ConnectException;
use GuzzleHttp\Exception\ClientException;
use GuzzleHttp\Exception\ServerException;

define('CDXENDPOINT', 'http://wayback.archive-it.org/all/timemap/cdx?url=');
define('WAYBACKENDPOINT', 'http://wayback.archive-it.org/');

$options = getopt('c:u:');
$collection_id = $options['c'];
$path_to_url_list = $options['u'];
$urls = file($path_to_url_list);

$temp_filename = uniqid();

$path_to_log = 'archiveit_log.log';
$log = new Monolog\Logger('Archive-It Auditor Log');
$log_stream_handler= new Monolog\Handler\StreamHandler($path_to_log, Logger::INFO);
$log->pushHandler($log_stream_handler);

$url_num = 0;
foreach ($urls as $url) {
    $url_num++;
    $cdx = get_cdx($url, $log);

    $wayback_url = WAYBACKENDPOINT . $collection_id . '/' . $cdx[1] . 'id_/' . $cdx[2];
    $content = get_content($wayback_url, $log);
    file_put_contents($temp_filename, $content);

    compare_digests($temp_filename, $cdx, $log);   

    unlink($temp_filename);
}

print "Audit of $url_num ULRs complete. Results are in $path_to_log.\n";

/**
 * Gets the entry in the CDX/C record that we use to validate the URL.
 *
 * @param string $url
 *   The URL to validate.
 * @param object $log
 *   The Monolog log object.
 *
 * @return array
 *   An array version of the CDX/C record entry.
 */
function get_cdx($url) {
    $cdx_entries = array();
    $client = new GuzzleHttp\Client();
    $cdx_request = CDXENDPOINT . trim($url);
    $res = $client->request('GET', $cdx_request);
    $cdx_record = $res->getBody();
    $cdx_rows = preg_split("/\\r\\n|\\r|\\n/", $cdx_record);
    foreach ($cdx_rows as $key => $entry) {
        if (strlen($entry)) {
            $entry_record = explode(' ', $entry);
            // We only want entries resulting from an HTTP 200 response.
            if ($entry_record[4] == '200') {
                $cdx_entries[] = $entry_record;
            }
        }
    }

    // @todo: In production, there may be more than one 200 record, so we'll
    // need to sort by timestamp and take the most recent.
    $cdx = $cdx_entries[0];
    return $cdx;
}

/**
 * Gets the content at the URL.
 *
 * @param string $wayback_url
 *   The URL of the Arcive-It API to fetch the file content.
 * @param object $log
 *   The Monolog log object.
 *
 * @return string
 *   The file's contents.
 */
function get_content($wayback_url, $log) {
    $client = new GuzzleHttp\Client();
    $res = $client->request('GET', $wayback_url);
    return $res->getBody();
}

/**
 * Compares the sha1 checksum of the retrieved file with the sha1 in the CDX/C record.
 *
 * @param string $temp_filename
 *   The name of the retrived file.
 * @param array $cdx
 *   The CDX/C record array.
 * @param object $log
 *   The Monolog log object.
 *
 * @return string
 *   The file's contents.
 */
function compare_digests($temp_filename, $cdx, $log) {
    // Get the raw binary digest of the retrieved file.
    $sha1 = sha1_file($temp_filename, TRUE);
    // Archive-It stores its sha1 digests in Base32, so we need to
    // convert the binary to Base32 for comparison.
    $base32_encoded = Base32::encode($sha1);
    if ($base32_encoded == $cdx[5]) {
        $log->addInfo("CDX/C checksum for {$cdx[2]} validated.");
    }
    else {
        $log->addError("CDX/C checksum for {$cdx[2]} invalid.");
    }
}
